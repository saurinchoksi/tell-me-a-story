# 2026-01-24 — Day 5: Hallucination Filtering Complete

## What happened

Deep dive into hallucination detection and filtering. Started with word-level signals, discovered their limits, moved to segment-level signals, and landed on a two-layer approach that produces honest transcripts.

## The hallucination journey

**Word-level signals (built earlier):**
- `filter_zero_duration_words()` — catches fabricated words where `end == start`
- `filter_low_probability_words()` — catches words with probability < 0.5

These removed 200+ "silly silly silly" repetitions. But one UNKNOWN remained.

**The problem:** Some hallucinated words have *high* probability (0.85+). Whisper is confidently wrong. Word-level signals weren't enough.

**Segment-level exploration:**

Ran exploration to see what MLX Whisper gives us per segment:

| Attribute | Real Speech | Hallucination |
|-----------|-------------|---------------|
| `temperature` | 0.0 | 1.0 |
| `compression_ratio` | 1.0-1.5 | 26.8 |
| `no_speech_prob` | ~1e-12 | ~1e-11 (not useful) |

**Key insight:** `no_speech_prob` stays low during hallucination because real speech IS happening — Arti speaking quietly at the end of the recording. The model correctly detects speech, it just can't decode it and invents words.

**The solution:** Two-layer filtering with different purposes:

1. **Segment filter** (`mark_hallucinated_segments`) — runs before word extraction
   - Catches: `temperature == 1.0` OR `compression_ratio > 2.5`
   - Action: Replace segment text with `[unintelligible]`
   - Purpose: Mark real-but-unclear speech honestly

2. **Word filters** — run after word extraction
   - Catch: zero-duration words, low-probability words
   - Action: Remove entirely
   - Purpose: Delete fabricated content that never existed

## The key distinction

Almost made the mistake of removing word filters because "segment filter handles it." But they do different things:

- **`[unintelligible]`** = real speech we can't decode → preserve, mark, can fill in later
- **Filtered words** = fabricated content from nothing → delete, they're lies

"Honest transcripts, not clean transcripts."

## Research: Prevention vs post-filtering

Researched whether we should prevent hallucinations (VAD preprocessing) or filter them after.

**VAD preprocessing:**
- Silero VAD only 61% accurate on noisy audio
- Can miss real speech — one example skipped actual dialogue after noise
- Would risk losing Arti's quiet moments

**Post-filtering (our approach):**
- Keeps all real speech
- Marks what we can't decode as `[unintelligible]`
- Research validates: "delooping+BoH approach yields nearly as good performance"

**Decision:** Stick with post-filtering. We'd rather have `[unintelligible]` than lose the fact that Arti spoke.

## Build vs buy reflection

Could have used WhisperX, faster-whisper, or whisper-timestamped — they solve similar problems.

Why we built custom:
1. **Learning** — writing alignment logic taught how diarization and transcription fit together
2. **Control** — `[unintelligible]` approach is specific to our use case
3. **Simplicity** — ~200 lines we fully understand vs library with dependencies and opinions

**The pattern:**
- First time: build it yourself, learn the domain
- Second time: use the library, customize where needed
- Third time: you know when the library is wrong

Next transcription project would probably start with WhisperX. But the value of building custom isn't the code — it's the judgment.

## Pipeline now

```
audio → transcribe → mark_hallucinated_segments → extract words → diarize → filter_zero_duration → filter_low_probability → align → format
```

Output for hallucinated segment: `[334.9 - 338.0] UNKNOWN: [unintelligible]`

## Tests

- 43 fast tests passing
- 6 slow integration tests passing
- New tests for `mark_hallucinated_segments()`

## What's next

- JSON output — save sessions to `sessions/processed/`
- More test recordings to validate
- Story element extraction (characters, worlds, plot beats)

---

*Solid day. Went from "1 remaining UNKNOWN" to understanding the full hallucination landscape to a two-layer honest filtering system.*
