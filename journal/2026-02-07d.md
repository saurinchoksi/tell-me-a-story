# 2026-02-07d — Hallucination Ground Truth + Diarization Enrichment

## Session Type
Build — Hallucination analysis with real data, diarization-into-transcript architecture

## What Happened

### Hallucination Ground Truth from Real Data
Walked through every word below probability 0.5 in the session 00000000-000001 transcript. 24 words flagged. Choksi provided ground truth for each.

**4 confirmed hallucinations:** seg 5 "Well." (0.133), seg 13 "Right." (0.086), seg 99 "Okay." (0.240), seg 100 "Okay." (0.304). All single-word filler segments.

**20 real words with low probability:** "Dad," (0.109), "His" (0.010), multiple "The..." segments, Sanskrit names after correction. Low prob comes from quiet speakers (Arti), Sanskrit names Whisper can't decode, seek-window restarts, natural hesitations.

**Key finding: no probability threshold cleanly separates hallucinations from real speech.** A blanket `prob < 0.5` flag produces massive false positives. Even `prob < 0.2` catches real speech ("Dad," at 0.109, "His" at 0.010). One sample isn't enough to commit to any rule.

### Choksi's Ground Truth Corrections
- Seg 30 "The rich father." → actually Arti saying "Well, which father?"
- Segs 33-35 "The..." → Choksi saying "Dhritarashtra", prompting "Dhi...", Arti repeating — real speech Whisper couldn't decode
- Segs 99-100 "Okay." → hallucinations, not real speech

### Diarization as Hallucination Signal
Cross-referenced 4 hallucinations against diarization.json. 3 of 4 fall in silence gaps — pyannote independently confirms nobody was talking. The 4th (seg 5) is a seek-boundary duplicate overlapping the real segment temporally — needs duplicate detection instead.

This is the real leverage: two independent systems (Whisper + pyannote) disagreeing about whether speech exists = strong signal.

### Diarization Merged into Transcript
Decision: merge diarization into the transcript as another enrichment stage rather than keeping it as a separate artifact. One source of truth.

Word-level, not segment-level — Code surfaced that the SYNC spec said segment-level but `query.py` already does word-level assignment, and a single Whisper segment can contain two speakers. Corrected to word-level before Code executed.

Code completed: `src/enrichment.py`, 112 tests passing, schema 1.2.0. Coverage-clamping bug caught in self-review.

## Key Decisions

- **No hallucination rules to build yet.** Need more sessions through pipeline + ground truth to establish patterns. Validation tool already supports eyeballing low-confidence segments.
- **Diarization coverage is the primary hallucination signal**, not word probability alone.
- **Word-level speaker enrichment**, not segment-level. Finest grain, can always derive segment from words.
- **`diarization.json` stays as raw artifact.** Enrichment reads it, transcript becomes the single read point.

## What's Next
- Re-run pipeline on 00000000-000001 to produce 1.2.0 transcript
- Process more sessions to build ground truth corpus
- Build log mockups to review (content work)
