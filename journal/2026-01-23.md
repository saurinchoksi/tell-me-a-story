# 2026-01-23 — Day 4: Leading Fragments + Model Clarity

## What happened

Picked up from the 7 remaining UNKNOWNs after yesterday's merge logic. Investigated what they actually were, found a pattern, built a fix.

## The remaining UNKNOWNs

Ran the pipeline and examined the 7 cases:

| Time | Text | Pattern |
|------|------|---------|
| 1.2-2.2 | "Okay," | Start of recording |
| 44.4-45.1 | "That's" | Start of "That's right, Yudhishthira" |
| 138.5-139.0 | "The" | Start of "The blind father" |
| 147.4-149.4 | "The? The" | Arti trying to say "The Trasht" |
| 316.5-316.9 | "I" | Start of "I just told you" |
| 334.9-335.5 | "He knows." | Hallucination |
| 337.1-337.9 | "He knows..." | Hallucination |

**The pattern:** The first 5 are all turn-starts that diarization missed. They're fragments right before the next speaker's utterance — in fact, they're *part of* the next speaker's turn.

**The insight:** These UNKNOWNs end exactly where (or very close to where) the next utterance starts. Zero gap, or near-zero. That's not coincidence — it's the same speech event, diarization just missed the boundary.

## The fix: assign_leading_fragments

New function that assigns UNKNOWNs to the next speaker if the gap is ≤0.5s:

```python
def assign_leading_fragments(utterances: list[dict], max_gap: float = 0.5) -> list[dict]:
    for i, utt in enumerate(utterances):
        if utt["speaker"] is None and i < len(utterances) - 1:
            next_utt = utterances[i + 1]
            gap = next_utt["start"] - utt["end"]
            
            if gap <= max_gap and next_utt["speaker"] is not None:
                # Assign to next speaker
```

Time-based threshold felt more principled than just "assign to whoever comes next."

**Result:** 75 → 1 UNKNOWN (down from 75 → 7 after yesterday's merge)

## The remaining hallucination

The last UNKNOWN is at the end of the recording. Whisper heard Arti say something quiet (actually about her blanket) but filled in "And we'll do it again tomorrow" — contextually plausible given I'd just said "we can talk about it again tomorrow."

Two types of hallucinations:
1. **Random repetition** — "He knows. He knows. He knows." (noise/silence)
2. **Contextual** — "And we'll do it again tomorrow" (quiet speech, model guesses)

The second is sneakier because it sounds right. Hallucination filtering is a separate task.

## Model clarification

Cleared up confusion about what models we're using:

| Library | Model | Job |
|---------|-------|-----|
| MLX Whisper | whisper-large-v3-turbo | Speech → text |
| pyannote.audio | speaker-diarization-community-1 | Speaker identification |

Whisper is a speech recognition model (not an LLM). Pyannote is a speaker diarization model. Both are specialized audio AI, not general-purpose.

**Embeddings:** Pyannote represents each voice as a list of hundreds of numbers — a point in mathematical space. Similar voices cluster together. This is how it figures out which segments came from the same person.

## Pipeline now

```
audio file
    → transcribe (Whisper large)
    → diarize (pyannote)
    → align_words_to_speakers
    → group_words_by_speaker
    → merge_unknown_utterances (same speaker sandwich)
    → assign_leading_fragments (close to next speaker) ← NEW
    → consolidate_utterances
    → format_transcript
```

## Tests

7 new tests for assign_leading_fragments:
- Basic case (within gap threshold)
- Gap too large
- UNKNOWN at end of list
- Next utterance also UNKNOWN
- Empty input
- No UNKNOWNs
- Custom threshold

20 total align tests passing.

## Side conversation: AI skepticism

Talked with a former colleague who thinks "AI will fizzle." Showed him the job tracker I built. He critiqued the UX polish rather than seeing the capability — that I built a custom tool in an afternoon that would've taken weeks before.

The real shift: "Oh, I could just... make that." Small problems getting solved that were never worth a developer's time. That's not a fad.

## What's next

- Hallucination filtering (trailing audio artifacts)
- Save transcripts to file
- Story element extraction (characters, worlds, plot beats)
