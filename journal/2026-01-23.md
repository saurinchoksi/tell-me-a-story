# 2026-01-23 — Day 4: Leading Fragments + Model Clarity

## What happened

Picked up from the 7 remaining UNKNOWNs after yesterday's merge logic. Investigated what they actually were, found a pattern, built a fix.

## The remaining UNKNOWNs

Ran the pipeline and examined the 7 cases:

| Time | Text | Pattern |
|------|------|---------|
| 1.2-2.2 | "Okay," | Start of recording |
| 44.4-45.1 | "That's" | Start of "That's right, Yudhishthira" |
| 138.5-139.0 | "The" | Start of "The blind father" |
| 147.4-149.4 | "The? The" | Arti trying to say "The Trasht" |
| 316.5-316.9 | "I" | Start of "I just told you" |
| 334.9-335.5 | "He knows." | Hallucination |
| 337.1-337.9 | "He knows..." | Hallucination |

**The pattern:** The first 5 are all turn-starts that diarization missed. They're fragments right before the next speaker's utterance — in fact, they're *part of* the next speaker's turn.

**The insight:** These UNKNOWNs end exactly where (or very close to where) the next utterance starts. Zero gap, or near-zero. That's not coincidence — it's the same speech event, diarization just missed the boundary.

## The fix: assign_leading_fragments

New function that assigns UNKNOWNs to the next speaker if the gap is ≤0.5s:

```python
def assign_leading_fragments(utterances: list[dict], max_gap: float = 0.5) -> list[dict]:
    for i, utt in enumerate(utterances):
        if utt["speaker"] is None and i < len(utterances) - 1:
            next_utt = utterances[i + 1]
            gap = next_utt["start"] - utt["end"]
            
            if gap <= max_gap and next_utt["speaker"] is not None:
                # Assign to next speaker
```

Time-based threshold felt more principled than just "assign to whoever comes next."

**Result:** 75 → 1 UNKNOWN (down from 75 → 7 after yesterday's merge)

## The remaining hallucination

The last UNKNOWN is at the end of the recording. Whisper heard Arti say something quiet (actually about her blanket) but filled in "And we'll do it again tomorrow" — contextually plausible given I'd just said "we can talk about it again tomorrow."

Two types of hallucinations:
1. **Random repetition** — "He knows. He knows. He knows." (noise/silence)
2. **Contextual** — "And we'll do it again tomorrow" (quiet speech, model guesses)

The second is sneakier because it sounds right. Hallucination filtering is a separate task.

## Model clarification

Cleared up confusion about what models we're using:

| Library | Model | Job |
|---------|-------|-----|
| MLX Whisper | whisper-large-v3-turbo | Speech → text |
| pyannote.audio | speaker-diarization-community-1 | Speaker identification |

Whisper is a speech recognition model (not an LLM). Pyannote is a speaker diarization model. Both are specialized audio AI, not general-purpose.

**Embeddings:** Pyannote represents each voice as a list of hundreds of numbers — a point in mathematical space. Similar voices cluster together. This is how it figures out which segments came from the same person.

## Pipeline now

```
audio file
    → transcribe (Whisper large)
    → diarize (pyannote)
    → align_words_to_speakers
    → group_words_by_speaker
    → merge_unknown_utterances (same speaker sandwich)
    → assign_leading_fragments (close to next speaker) ← NEW
    → consolidate_utterances
    → format_transcript
```

## Tests

7 new tests for assign_leading_fragments:
- Basic case (within gap threshold)
- Gap too large
- UNKNOWN at end of list
- Next utterance also UNKNOWN
- Empty input
- No UNKNOWNs
- Custom threshold

20 total align tests passing.

## Side conversation: AI skepticism

Talked with a former colleague who thinks "AI will fizzle." Showed him the job tracker I built. He critiqued the UX polish rather than seeing the capability — that I built a custom tool in an afternoon that would've taken weeks before.

The real shift: "Oh, I could just... make that." Small problems getting solved that were never worth a developer's time. That's not a fad.

## What's next

- JSON saving to `sessions/processed/`
- Hallucination filtering (trailing audio artifacts)
- Story element extraction (characters, worlds, plot beats)

---

## Session 2: Architecture + Refactoring

### Code structure cleanup

Realized `align.py` was doing too much — it had alignment functions *and* orchestration logic in `__main__`. Split responsibilities:

- **`align.py`** — pure alignment functions, no orchestration
- **`pipeline.py`** (new) — imports from transcribe, diarize, align; runs the full pipeline

Added `align()` wrapper function that chains all the alignment steps. Now all modules follow the same pattern:

| Module | Entry point |
|--------|-------------|
| `transcribe.py` | `transcribe()` |
| `diarize.py` | `diarize()` |
| `align.py` | `align()` |
| `pipeline.py` | `run_pipeline()` |

### JSON schema design

Designed the output format for saving sessions. Key decisions:

- **JSON as canonical format** — preserves word-level timestamps for future caption sync
- **Markdown later** — human-readable view, generated from JSON
- **`stories` array** — future-proofs for splitting one recording into multiple stories

```json
{
  "meta": {
    "source_audio": "2026-01-15_bedtime.m4a",
    "audio_duration": 423.5,
    "transcribed_at": "2026-01-23T10:30:00Z",
    "speakers_detected": ["SPEAKER_00", "SPEAKER_01"]
  },
  "stories": [
    {
      "story_id": "2026-01-15_bedtime",
      "title": null,
      "audio_range": [0.0, 423.5],
      "extracted": null,
      "utterances": [...]
    }
  ]
}
```

The vision: mobile browser → pick a session → audio plays with synced captions like Apple Music lyrics.

### Folder naming journey

`stories/` → `pipeline/` → `sessions/`

Landed on `sessions/` because:
- The folder holds *data* (recording sessions), not *code* (the pipeline)
- "Sessions" describes what's inside — each recording sitting with its outputs
- Sets up the mental model: one session = one audio + one JSON + (eventually) one Markdown

Structure now:
```
sessions/
  audio/      ← source recordings (gitignored)
  processed/  ← JSON output (gitignored)
```

### Claude Code setup

Ran `/init` to create `CLAUDE.md`. Added project context:
- Design principles (Victor, Papert, Weiser, Arti Test)
- Output format schema
- Current state and next steps

Used SYNC.md handoff pattern to have Claude Code do the folder renames. Worked cleanly both times.

### Tests

Added `test_align_full_pipeline` for the new `align()` wrapper. 21 align tests, 33 total tests passing.
