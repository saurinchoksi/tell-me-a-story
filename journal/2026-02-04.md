# 2026-02-04 — Hallucination Analysis

## Summary
Cross-referenced validation notes against transcript segment metadata. Discovered current hallucination detection (temp/compression) catches nothing. Word probability is the real signal.

## The Analysis

Started with validation notes from session 00000000-000000. Eight notes total:
- 4 hallucinated/duplicate segments
- 3 missing quiet speech (child voice not captured)
- 1 duplicate transcription

Built analysis script to check what detection criteria would catch each issue.

## Key Finding: Current Filters Are Useless

| Criterion | Segments Caught |
|-----------|-----------------|
| temperature >= 1.0 | 0/5 |
| compression_ratio > 2.5 | 0/5 |
| **min_word_prob < 0.5** | **3/5** |

The temperature filter never fires because Whisper stays at 0.0 or 0.2 even when hallucinating. Compression ratio came close on one segment (2.39, just under 2.5 threshold).

## Segment-by-Segment

| Segment | Text | min_prob | Detection |
|---------|------|----------|-----------|
| 5 | "Well." (duplicate) | 0.133 | ✅ LOW_PROB |
| 13 | "Right." (hallucinated) | 0.086 | ✅ LOW_PROB |
| 23 | "Duryodhan was..." (hallucinated) | 0.745 | ❌ None |
| 87 | "Okay." (wrong content) | 0.241 | ✅ LOW_PROB |

Segment 23 is the stubborn one. High probability but still fabricated. Could be caught by lowering compression threshold to 2.4, or by detecting repeated text across consecutive segments.

## Missing Speech is a Different Problem

Three notes flagged missing Arti speech. These aren't transcription failures — the audio wasn't captured. No filter can help. Needs:
- Better mic placement
- Higher gain
- Voice activity detection at audio level

## Architecture Decision

Per yesterday's principles: add metadata, filter at query time.

**Implemented:** `_min_word_prob` field on every segment. Computed in `clean_transcript()` after zero-duration garbage removal. Schema bumped to 1.1.0.

Claude Code had already executed this by the time I wrote the plan. Good outcome — we converged on the same design.

## SYNC Processing

Cleared the handoff queue:
- Moved `_min_word_prob` task to SYNC-LOG.md
- Moved screenshot task to SYNC-LOG.md
- Both sections now empty

## What's Next

1. Use `_min_word_prob` in query layer — add filter predicate
2. Consider segment 23 edge case — lower compression threshold? duplicate text detection?
3. More validation sessions for calibration data

## Course Correction: Reverted _min_word_prob

Later in the day, realized the segment-level `_min_word_prob` field was unnecessary. The existing word-level `min_probability()` filter in `filters.py` already handles these cases.

**The logic:**
- Hallucinated segments like "Right." and "Well." are single words with low probability
- Word filter removes them → segment becomes empty
- Segment filter removes whole segment → same outcome
- Simpler code wins

**Action:** `git revert 6ecfe87` → clean revert, schema back to 1.0.0, 67 tests passing.

**Insight:** When considering segment-level vs word-level filtering, check if word-level already solves the problem.

Also removed "High temp/compression analysis" from deferred tasks — 0% catch rate means it's a dead end.

## Technical Artifacts
- Revert commit: `ac54a86`
- CURRENT.md updated with course correction
- SYNC-LOG.md has revert entry
- 67 fast tests passing

---

## Addendum: Filter Architecture Audit

Followed up on the revert with a full audit of `filters.py` and how filtering flows through the system.

**Discovery:** Most filters were redundant or theoretical.

| Filter | Status | Reason |
|--------|--------|--------|
| `has_duration` | Redundant | `clean_transcript()` already removes zero-duration words |
| `has_content` | Theoretical | Never seen empty-word cases in actual transcripts |
| `min_probability` | **Needed** | The real hallucination filter |
| `all_of`, `apply_filter`, `DEFAULT_FILTER` | Removed | Only existed to support the redundant filters |

**Validator gap identified:** The validator tool serves raw `transcript.json` with no filtering. Words are color-coded by probability, but hallucinations still appear. Need server-side filtering with UI control.

**Code executed:** Simplified `filters.py` from ~80 to ~23 lines. Just `Predicate` type alias + `min_probability(threshold)`. `query.py` filtering is now opt-in.

**Next:** Wire filter into validator endpoint (`?min_prob=0.5`), add UI toggle.
